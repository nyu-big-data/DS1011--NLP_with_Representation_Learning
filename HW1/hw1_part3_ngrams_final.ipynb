{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DS-GA 1011 Homework 1 - Part 3\n",
    "## N-Gram Language Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-08T03:35:56.543910Z",
     "start_time": "2020-10-08T03:35:56.540906Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-08T03:35:57.226988Z",
     "start_time": "2020-10-08T03:35:57.216611Z"
    }
   },
   "outputs": [],
   "source": [
    "def load_wikitext(filename='wikitext2-sentencized.json'):\n",
    "    if not os.path.exists(filename):\n",
    "        !wget \"https://nyu.box.com/shared/static/9kb7l7ci30hb6uahhbssjlq0kctr5ii4.json\" -O $filename\n",
    "    \n",
    "    datasets = json.load(open(filename, 'r'))\n",
    "    for name in datasets:\n",
    "        datasets[name] = [x.split() for x in datasets[name]]\n",
    "    vocab = list(set([t for ts in datasets['train'] for t in ts]))      \n",
    "    print(\"Vocab size: %d\" % (len(vocab)))\n",
    "    return datasets, vocab\n",
    "\n",
    "def perplexity(model, sequences):\n",
    "    n_total = 0\n",
    "    logp_total = 0\n",
    "    for sequence in sequences:\n",
    "        logp_total += model.sequence_logp(sequence)\n",
    "        n_total += len(sequence) + 1  \n",
    "    ppl = 2 ** (- (1.0 / n_total) * logp_total)  \n",
    "    return ppl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Additive Smoothing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fill in the ngram_prob method in the class below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-08T03:35:59.123677Z",
     "start_time": "2020-10-08T03:35:59.112999Z"
    }
   },
   "outputs": [],
   "source": [
    "class NGramAdditive(object):\n",
    "    def __init__(self, n, delta, vsize):\n",
    "        self.n = n\n",
    "        self.delta = delta\n",
    "        self.count = defaultdict(lambda: defaultdict(float))\n",
    "        self.total = defaultdict(float)\n",
    "        self.vsize = vsize\n",
    "    \n",
    "    def estimate(self, sequences):\n",
    "        for sequence in sequences:\n",
    "            padded_sequence = ['<bos>']*(self.n-1) + sequence + ['<eos>']\n",
    "            for i in range(len(padded_sequence) - self.n+1):\n",
    "                ngram = tuple(padded_sequence[i:i+self.n])\n",
    "                prefix, word = ngram[:-1], ngram[-1]\n",
    "                self.count[prefix][word] += 1\n",
    "                self.total[prefix] += 1\n",
    "                \n",
    "    def sequence_logp(self, sequence):\n",
    "        padded_sequence = ['<bos>']*(self.n-1) + sequence + ['<eos>']\n",
    "        total_logp = 0\n",
    "        for i in range(len(padded_sequence) - self.n+1):\n",
    "            ngram = tuple(padded_sequence[i:i+self.n])\n",
    "            total_logp += np.log2(self.ngram_prob(ngram))\n",
    "        return total_logp\n",
    "\n",
    "    def ngram_prob(self, ngram):\n",
    "        # write me\n",
    "        prefix = ngram[:-1]\n",
    "        word = ngram[-1]\n",
    "        prob = (self.delta + self.count[prefix][word]) / (self.total[prefix] + self.delta * self.vsize)\n",
    "        return prob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"1.png\" width=600 height=600 />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-08T03:36:01.083134Z",
     "start_time": "2020-10-08T03:36:00.439392Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab size: 33175\n"
     ]
    }
   ],
   "source": [
    "datasets, vocab = load_wikitext()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline (Additive smoothing, n=2, delta=0.0005)) Train Perplexity: 90.228\n",
      "Baseline (Additive smoothing, n=2, delta=0.0005)) Valid Perplexity: 525.825\n",
      "Baseline (Additive smoothing, n=3, delta=0.0005)) Train Perplexity: 26.768\n",
      "Baseline (Additive smoothing, n=3, delta=0.0005)) Valid Perplexity: 2577.128\n",
      "Baseline (Additive smoothing, n=4, delta=0.0005)) Train Perplexity: 19.947\n",
      "Baseline (Additive smoothing, n=4, delta=0.0005)) Valid Perplexity: 9570.901\n"
     ]
    }
   ],
   "source": [
    "delta = 0.0005\n",
    "for n in [2, 3, 4]:\n",
    "    lm = NGramAdditive(n=n, delta=delta, vsize=len(vocab)+1)  # +1 is for <eos>\n",
    "    lm.estimate(datasets['train'])\n",
    "\n",
    "    print(\"Baseline (Additive smoothing, n=%d, delta=%.4f)) Train Perplexity: %.3f\" % (n, delta, perplexity(lm, datasets['train'])))\n",
    "    print(\"Baseline (Additive smoothing, n=%d, delta=%.4f)) Valid Perplexity: %.3f\" % (n, delta, perplexity(lm, datasets['valid'])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Is 0.005 a good value for $\\delta$? Compare the model's perplexity across several orders of magnitude of $\\delta$ (e.g., 0.0005, 0.005, 0.05, 0.5, and 1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline (Additive smoothing, n=2, delta=0.0005)) Train Perplexity: 90.228\n",
      "Baseline (Additive smoothing, n=2, delta=0.0005)) Valid Perplexity: 525.825\n",
      "Baseline (Additive smoothing, n=2, delta=0.0050)) Train Perplexity: 138.787\n",
      "Baseline (Additive smoothing, n=2, delta=0.0050)) Valid Perplexity: 475.942\n",
      "Baseline (Additive smoothing, n=2, delta=0.0500)) Train Perplexity: 331.400\n",
      "Baseline (Additive smoothing, n=2, delta=0.0500)) Valid Perplexity: 665.990\n",
      "Baseline (Additive smoothing, n=2, delta=0.5000)) Train Perplexity: 1133.768\n",
      "Baseline (Additive smoothing, n=2, delta=0.5000)) Valid Perplexity: 1411.721\n",
      "Baseline (Additive smoothing, n=2, delta=1.0000)) Train Perplexity: 1695.477\n",
      "Baseline (Additive smoothing, n=2, delta=1.0000)) Valid Perplexity: 1892.272\n",
      "Baseline (Additive smoothing, n=3, delta=0.0005)) Train Perplexity: 26.768\n",
      "Baseline (Additive smoothing, n=3, delta=0.0005)) Valid Perplexity: 2577.128\n",
      "Baseline (Additive smoothing, n=3, delta=0.0050)) Train Perplexity: 116.398\n",
      "Baseline (Additive smoothing, n=3, delta=0.0050)) Valid Perplexity: 2875.057\n",
      "Baseline (Additive smoothing, n=3, delta=0.0500)) Train Perplexity: 733.721\n",
      "Baseline (Additive smoothing, n=3, delta=0.0500)) Valid Perplexity: 4652.515\n",
      "Baseline (Additive smoothing, n=3, delta=0.5000)) Train Perplexity: 4701.752\n",
      "Baseline (Additive smoothing, n=3, delta=0.5000)) Valid Perplexity: 9198.110\n",
      "Baseline (Additive smoothing, n=3, delta=1.0000)) Train Perplexity: 7453.415\n",
      "Baseline (Additive smoothing, n=3, delta=1.0000)) Valid Perplexity: 11318.403\n",
      "Baseline (Additive smoothing, n=4, delta=0.0005)) Train Perplexity: 19.947\n",
      "Baseline (Additive smoothing, n=4, delta=0.0005)) Valid Perplexity: 9570.901\n",
      "Baseline (Additive smoothing, n=4, delta=0.0050)) Train Perplexity: 139.759\n",
      "Baseline (Additive smoothing, n=4, delta=0.0050)) Valid Perplexity: 10697.654\n",
      "Baseline (Additive smoothing, n=4, delta=0.0500)) Train Perplexity: 1128.102\n",
      "Baseline (Additive smoothing, n=4, delta=0.0500)) Valid Perplexity: 13772.863\n",
      "Baseline (Additive smoothing, n=4, delta=0.5000)) Train Perplexity: 7471.095\n",
      "Baseline (Additive smoothing, n=4, delta=0.5000)) Valid Perplexity: 18588.889\n",
      "Baseline (Additive smoothing, n=4, delta=1.0000)) Train Perplexity: 11407.512\n",
      "Baseline (Additive smoothing, n=4, delta=1.0000)) Valid Perplexity: 20244.914\n"
     ]
    }
   ],
   "source": [
    "delta = 0.0005\n",
    "for n in [2, 3, 4]:\n",
    "    for delta in [0.0005, 0.005, 0.05, 0.5, 1]:\n",
    "        lm = NGramAdditive(n=n, delta=delta, vsize=len(vocab)+1)  # +1 is for <eos>\n",
    "        lm.estimate(datasets['train'])\n",
    "\n",
    "        print(\"Baseline (Additive smoothing, n=%d, delta=%.4f)) Train Perplexity: %.3f\" % (n, delta, perplexity(lm, datasets['train'])))\n",
    "        print(\"Baseline (Additive smoothing, n=%d, delta=%.4f)) Valid Perplexity: %.3f\" % (n, delta, perplexity(lm, datasets['valid'])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpolation\n",
    "\n",
    "Implement interpolation smoothing, and find optimal settings of the hyperparameters ($\\lambda_1, \\ldots, \\lambda_n$), for each of $n \\in \\{2, 3, 4\\}$. You can use grid search (i.e., systematically loop through a range of possible values). Show your results, including perplexity for all of the lambda values you have experimented with. Remember: hyperparameter optimization needs to be performed on the validation set -- do not touch the test set until the last section of this notebook!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-08T03:36:03.940517Z",
     "start_time": "2020-10-08T03:36:03.926282Z"
    }
   },
   "outputs": [],
   "source": [
    "class NGramInterpolation(object):\n",
    "    def __init__(self, n, lambdas, vsize, total_word_count):\n",
    "        self.n = n\n",
    "        self.lambdas = lambdas\n",
    "        self.count = defaultdict(lambda: defaultdict(float))\n",
    "        self.total = defaultdict(float)\n",
    "        self.vsize = vsize\n",
    "        self.total_word_count = total_word_count\n",
    "        \n",
    "    \n",
    "    def estimate(self, sequences):\n",
    "        for sequence in sequences:\n",
    "            padded_sequence = ['<bos>']*(self.n-1) + sequence + ['<eos>']\n",
    "            for i in range(self.n-1, len(padded_sequence)):\n",
    "                ngram = tuple(padded_sequence[i-self.n+1:i+1])\n",
    "                for j in range(1, self.n):\n",
    "                    prefix, word = ngram[:j], ngram[j]\n",
    "                    self.count[prefix][word] += 1\n",
    "                    self.total[prefix] += 1 \n",
    "                    self.total[word] += 1\n",
    "                    \n",
    "    def sequence_logp(self, sequence):\n",
    "        padded_sequence = ['<bos>']*(self.n-1) + sequence + ['<eos>']\n",
    "        total_logp = 0\n",
    "        for i in range(len(padded_sequence) - self.n+1):\n",
    "            ngram = tuple(padded_sequence[i:i+self.n])\n",
    "            total_logp += np.log2(self.ngram_prob(ngram, self.n, self.lambdas[-1]))\n",
    "        return total_logp\n",
    "\n",
    "    def ngram_prob(self, ngram, cur_n, cur_lambda):\n",
    "        prefix, word = ngram[:-1], ngram[-1]\n",
    "        # we use a recursive way to compute the probability\n",
    "        # cur_n: the current ngram that we are dealing with\n",
    "        # cur_lambda: current lambda value\n",
    "        if cur_n == 1:\n",
    "            # use additive smoothing when computing the unigram\n",
    "            prob = (self.total[word] + 0.005) / (self.total_word_count + 0.005 * self.vsize) * cur_lambda\n",
    "            return prob\n",
    "        \n",
    "        if cur_n > 1:\n",
    "            # self.total[prefix]: the \n",
    "            if self.total[prefix] == 0:\n",
    "                prob = 0\n",
    "            else:\n",
    "                prob = self.count[prefix][word] / self.total[prefix]\n",
    "            return prob * cur_lambda + self.ngram_prob(ngram, cur_n - 1, self.lambdas[cur_n - 2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"2.png\" width=600 height=600 />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-08T03:36:04.771284Z",
     "start_time": "2020-10-08T03:36:04.666423Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1924754\n"
     ]
    }
   ],
   "source": [
    "total_wc = len([t for ts in datasets['train'] for t in ts])\n",
    "print(total_wc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-08T03:36:20.764971Z",
     "start_time": "2020-10-08T03:36:20.760806Z"
    }
   },
   "outputs": [],
   "source": [
    "#Random Search\n",
    "def grid_search_lambdas(n, n_param_sets):\n",
    "    lambdas_set = [] \n",
    "    for i in range(n_param_sets):\n",
    "        rand_arr = np.random.rand(1,n)\n",
    "        normalised_rand_arr = np.round(rand_arr/rand_arr.sum(),2).reshape((n, 1))\n",
    "        lambdas_set.append(normalised_rand_arr)\n",
    "    return lambdas_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline (Interpolation, n=2, lamdas=[[0.19]\n",
      " [0.81]]) Train Perplexity: 89.162\n",
      "Baseline (Interpolation, n=2, lamdas=[[0.19]\n",
      " [0.81]]) Valid Perplexity: 311.151\n",
      "Baseline (Interpolation, n=2, lamdas=[[0.12]\n",
      " [0.88]]) Train Perplexity: 84.194\n",
      "Baseline (Interpolation, n=2, lamdas=[[0.12]\n",
      " [0.88]]) Valid Perplexity: 330.768\n",
      "Baseline (Interpolation, n=2, lamdas=[[0.06]\n",
      " [0.94]]) Train Perplexity: 80.488\n",
      "Baseline (Interpolation, n=2, lamdas=[[0.06]\n",
      " [0.94]]) Valid Perplexity: 373.063\n",
      "Baseline (Interpolation, n=2, lamdas=[[0.77]\n",
      " [0.23]]) Train Perplexity: 202.676\n",
      "Baseline (Interpolation, n=2, lamdas=[[0.77]\n",
      " [0.23]]) Valid Perplexity: 399.260\n",
      "Baseline (Interpolation, n=2, lamdas=[[0.5]\n",
      " [0.5]]) Train Perplexity: 124.189\n",
      "Baseline (Interpolation, n=2, lamdas=[[0.5]\n",
      " [0.5]]) Valid Perplexity: 315.820\n",
      "----------\n",
      "Best (Interpolation smoothing, n=2, lamdas=[[0.19]\n",
      " [0.81]]) Valid Perplexity: 311.151\n",
      "\n",
      "Baseline (Interpolation, n=3, lamdas=[[0.39]\n",
      " [0.54]\n",
      " [0.07]]) Train Perplexity: 12.191\n",
      "Baseline (Interpolation, n=3, lamdas=[[0.39]\n",
      " [0.54]\n",
      " [0.07]]) Valid Perplexity: 349.223\n",
      "Baseline (Interpolation, n=3, lamdas=[[0.07]\n",
      " [0.67]\n",
      " [0.25]]) Train Perplexity: 8.691\n",
      "Baseline (Interpolation, n=3, lamdas=[[0.07]\n",
      " [0.67]\n",
      " [0.25]]) Valid Perplexity: 855.378\n",
      "Baseline (Interpolation, n=3, lamdas=[[0.37]\n",
      " [0.28]\n",
      " [0.35]]) Train Perplexity: 11.871\n",
      "Baseline (Interpolation, n=3, lamdas=[[0.37]\n",
      " [0.28]\n",
      " [0.35]]) Valid Perplexity: 357.064\n",
      "Baseline (Interpolation, n=3, lamdas=[[0.69]\n",
      " [0.02]\n",
      " [0.29]]) Train Perplexity: 20.978\n",
      "Baseline (Interpolation, n=3, lamdas=[[0.69]\n",
      " [0.02]\n",
      " [0.29]]) Valid Perplexity: 297.408\n",
      "Baseline (Interpolation, n=3, lamdas=[[0.17]\n",
      " [0.45]\n",
      " [0.38]]) Train Perplexity: 9.447\n",
      "Baseline (Interpolation, n=3, lamdas=[[0.17]\n",
      " [0.45]\n",
      " [0.38]]) Valid Perplexity: 522.651\n",
      "----------\n",
      "Best (Interpolation smoothing, n=3, lamdas=[[0.69]\n",
      " [0.02]\n",
      " [0.29]]) Valid Perplexity: 297.408\n",
      "\n",
      "Baseline (Interpolation, n=4, lamdas=[[0.25]\n",
      " [0.44]\n",
      " [0.13]\n",
      " [0.18]]) Train Perplexity: 3.140\n",
      "Baseline (Interpolation, n=4, lamdas=[[0.25]\n",
      " [0.44]\n",
      " [0.13]\n",
      " [0.18]]) Valid Perplexity: 645.675\n",
      "Baseline (Interpolation, n=4, lamdas=[[0.11]\n",
      " [0.35]\n",
      " [0.11]\n",
      " [0.43]]) Train Perplexity: 2.696\n",
      "Baseline (Interpolation, n=4, lamdas=[[0.11]\n",
      " [0.35]\n",
      " [0.11]\n",
      " [0.43]]) Valid Perplexity: 1227.201\n",
      "Baseline (Interpolation, n=4, lamdas=[[0.46]\n",
      " [0.18]\n",
      " [0.33]\n",
      " [0.03]]) Train Perplexity: 4.200\n",
      "Baseline (Interpolation, n=4, lamdas=[[0.46]\n",
      " [0.18]\n",
      " [0.33]\n",
      " [0.03]]) Valid Perplexity: 410.779\n",
      "Baseline (Interpolation, n=4, lamdas=[[0.26]\n",
      " [0.2 ]\n",
      " [0.31]\n",
      " [0.22]]) Train Perplexity: 3.220\n",
      "Baseline (Interpolation, n=4, lamdas=[[0.26]\n",
      " [0.2 ]\n",
      " [0.31]\n",
      " [0.22]]) Valid Perplexity: 628.059\n",
      "Baseline (Interpolation, n=4, lamdas=[[0.3 ]\n",
      " [0.11]\n",
      " [0.45]\n",
      " [0.14]]) Train Perplexity: 3.339\n",
      "Baseline (Interpolation, n=4, lamdas=[[0.3 ]\n",
      " [0.11]\n",
      " [0.45]\n",
      " [0.14]]) Valid Perplexity: 562.003\n",
      "----------\n",
      "Best (Interpolation smoothing, n=4, lamdas=[[0.46]\n",
      " [0.18]\n",
      " [0.33]\n",
      " [0.03]]) Valid Perplexity: 410.779\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for n in [2, 3, 4]:\n",
    "    best_valid_perplexity = 1e9\n",
    "    for lambdas in grid_search_lambdas(n, 5):\n",
    "        lm = NGramInterpolation(n = n, vsize = len(vocab) + 1, total_word_count = total_wc, lambdas = lambdas)  # +1 is for <eos>\n",
    "        lm.estimate(datasets['train'])\n",
    "        perplexity_train = perplexity(lm, datasets['train'])\n",
    "        perplexity_valid = perplexity(lm, datasets['valid'])\n",
    "        if perplexity_valid < best_valid_perplexity:\n",
    "            best_valid_perplexity = perplexity_valid\n",
    "            best_paramset = lambdas\n",
    "    \n",
    "        print(\"Baseline (Interpolation, n=%d, lamdas=%s) Train Perplexity: %.3f\" % (n, str(lambdas), perplexity_train))\n",
    "        print(\"Baseline (Interpolation, n=%d, lamdas=%s) Valid Perplexity: %.3f\" % (n, str(lambdas), perplexity_valid))\n",
    "    print(\"-\"*10)\n",
    "    print(\"Best (Interpolation smoothing, n=%d, lamdas=%s) Valid Perplexity: %.3f\" % (n, str(best_paramset), best_valid_perplexity))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Fine tune: n = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-08T03:35:00.173615Z",
     "start_time": "2020-10-08T03:35:00.171245Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#Previsous Best Result\n",
    "# ----------\n",
    "# Best (Interpolation smoothing, n=2, lamdas=[[0.19]\n",
    "#  [0.81]]) Valid Perplexity: 311.151"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "n=2\n",
    "lamdas= np.array([[0.19, 0.81]]).reshape((2,1))\n",
    "\n",
    "step = 0.01 \n",
    "lambdas_set = []\n",
    "\n",
    "new_lambdas = lambdas.copy()\n",
    "for i in range(0, 10): \n",
    "\n",
    "    new_lambdas[0][0] = new_lambdas[0][0] - step\n",
    "    new_lambdas[1][0] = new_lambdas[1][0] + step\n",
    "    lambdas_set.append(new_lambdas)\n",
    "    new_lambdas = new_lambdas.copy()\n",
    "    \n",
    "new_lambdas = lambdas.copy()\n",
    "for i in range(0, 10): \n",
    "\n",
    "    new_lambdas[0][0] = new_lambdas[0][0] + step\n",
    "    new_lambdas[1][0] = new_lambdas[1][0] - step\n",
    "    lambdas_set.append(new_lambdas)\n",
    "    new_lambdas = new_lambdas.copy()\n",
    "\n",
    "best_valid_perplexity = 1e9\n",
    "for lambdas in lambdas_set:\n",
    "    lm = NGramInterpolation(n = n, vsize = len(vocab) + 1, total_word_count = total_wc, lambdas = lambdas)  # +1 is for <eos>\n",
    "    lm.estimate(datasets['train'])\n",
    "    perplexity_train = perplexity(lm, datasets['train'])\n",
    "    perplexity_valid = perplexity(lm, datasets['valid'])\n",
    "    if perplexity_valid < best_valid_perplexity:\n",
    "        best_valid_perplexity = perplexity_valid\n",
    "        best_paramset = lambdas\n",
    "    \n",
    "    print(\"Baseline (Interpolation, n=%d, lamdas=%s) Train Perplexity: %.3f\" % (n, str(lambdas), perplexity_train))\n",
    "    print(\"Baseline (Interpolation, n=%d, lamdas=%s) Valid Perplexity: %.3f\" % (n, str(lambdas), perplexity_valid))\n",
    "print(\"-\"*10)\n",
    "print(\"Best (Interpolation smoothing, n=%d, lamdas=%s) Valid Perplexity: %.3f\" % (n, str(best_paramset), best_valid_perplexity))\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "n=2\n",
    "lamdas= np.array([[0.26, 0.74]]).reshape((2,1))\n",
    "\n",
    "step = 0.01 \n",
    "lambdas_set = []\n",
    "\n",
    "    \n",
    "new_lambdas = lambdas.copy()\n",
    "for i in range(0, 10): \n",
    "\n",
    "    new_lambdas[0][0] = new_lambdas[0][0] + step\n",
    "    new_lambdas[1][0] = new_lambdas[1][0] - step\n",
    "    lambdas_set.append(new_lambdas)\n",
    "    new_lambdas = new_lambdas.copy()\n",
    "\n",
    "best_valid_perplexity = 1e9\n",
    "for lambdas in lambdas_set:\n",
    "    lm = NGramInterpolation(n = n, vsize = len(vocab) + 1, total_word_count = total_wc, lambdas = lambdas)  # +1 is for <eos>\n",
    "    lm.estimate(datasets['train'])\n",
    "    perplexity_train = perplexity(lm, datasets['train'])\n",
    "    perplexity_valid = perplexity(lm, datasets['valid'])\n",
    "    if perplexity_valid < best_valid_perplexity:\n",
    "        best_valid_perplexity = perplexity_valid\n",
    "        best_paramset = lambdas\n",
    "    \n",
    "    print(\"Baseline (Interpolation, n=%d, lamdas=%s) Train Perplexity: %.3f\" % (n, str(lambdas), perplexity_train))\n",
    "    print(\"Baseline (Interpolation, n=%d, lamdas=%s) Valid Perplexity: %.3f\" % (n, str(lambdas), perplexity_valid))\n",
    "print(\"-\"*10)\n",
    "print(\"Best (Interpolation smoothing, n=%d, lamdas=%s) Valid Perplexity: %.3f\" % (n, str(best_paramset), best_valid_perplexity))\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Fine tune: n = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#PREVIOUS BEST Result: \n",
    "#Best (Interpolation smoothing, n=3, lamdas=[[0.69]\n",
    "#  [0.02]\n",
    "#  [0.29]]) Valid Perplexity: 297.408"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "n=3\n",
    "lambdas= np.array([[0.69, 0.02, 0.29]]).reshape((3,1))\n",
    "step = 0.01\n",
    "\n",
    "combinations = []\n",
    "for i in range(3): \n",
    "    ls = [0, 1, 2]\n",
    "    ls.remove(i)\n",
    "    for j in ls: \n",
    "        combinations.append((i, j))\n",
    "                            \n",
    "\n",
    "lambdas_set=[]\n",
    "for comb in combinations: \n",
    "    i, j = comb \n",
    "    new_lambdas = lambdas.copy()\n",
    "    new_lambdas[i][0] = lambdas[i][0] + step\n",
    "    new_lambdas[j][0] = lambdas[j][0] - step\n",
    "    lambdas_set.append(new_lambdas)                            \n",
    "\n",
    "best_valid_perplexity = 1e9\n",
    "for lambdas in lambdas_set:\n",
    "    lm = NGramInterpolation(n = n, vsize = len(vocab) + 1, total_word_count = total_wc, lambdas = lambdas)  # +1 is for <eos>\n",
    "    lm.estimate(datasets['train'])\n",
    "    perplexity_train = perplexity(lm, datasets['train'])\n",
    "    perplexity_valid = perplexity(lm, datasets['valid'])\n",
    "    if perplexity_valid < best_valid_perplexity:\n",
    "        best_valid_perplexity = perplexity_valid\n",
    "        best_paramset = lambdas\n",
    "    \n",
    "    print(\"Baseline (Interpolation, n=%d, lamdas=%s) Train Perplexity: %.3f\" % (n, str(lambdas), perplexity_train))\n",
    "    print(\"Baseline (Interpolation, n=%d, lamdas=%s) Valid Perplexity: %.3f\" % (n, str(lambdas), perplexity_valid))\n",
    "print(\"-\"*10)\n",
    "print(\"Best (Interpolation smoothing, n=%d, lamdas=%s) Valid Perplexity: %.3f\" % (n, str(best_paramset), best_valid_perplexity))\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#no better off\n",
    "lambdas= np.array([[0.7, 0.00, 0.3]]).reshape((3,1))\n",
    "\n",
    "lambdas_set=[lambdas]\n",
    "\n",
    "best_valid_perplexity = 1e9\n",
    "for lambdas in lambdas_set:\n",
    "    lm = NGramInterpolation(n = n, vsize = len(vocab) + 1, total_word_count = total_wc, lambdas = lambdas)  # +1 is for <eos>\n",
    "    lm.estimate(datasets['train'])\n",
    "    perplexity_train = perplexity(lm, datasets['train'])\n",
    "    perplexity_valid = perplexity(lm, datasets['valid'])\n",
    "    if perplexity_valid < best_valid_perplexity:\n",
    "        best_valid_perplexity = perplexity_valid\n",
    "        best_paramset = lambdas\n",
    "    \n",
    "    print(\"Baseline (Interpolation, n=%d, lamdas=%s) Train Perplexity: %.3f\" % (n, str(lambdas), perplexity_train))\n",
    "    print(\"Baseline (Interpolation, n=%d, lamdas=%s) Valid Perplexity: %.3f\" % (n, str(lambdas), perplexity_valid))\n",
    "print(\"-\"*10)\n",
    "print(\"Best (Interpolation smoothing, n=%d, lamdas=%s) Valid Perplexity: %.3f\" % (n, str(best_paramset), best_valid_perplexity))\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Fine tune: n = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#PREVIOUS BEST Result:\n",
    "# Best (Interpolation smoothing, n=4, lamdas=[[0.46]\n",
    "#  [0.18]\n",
    "#  [0.33]\n",
    "#  [0.03]]) Valid Perplexity: 410.779"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "n=4\n",
    "lambdas= np.array([[0.46, 0.18, 0.33, 0.03]]).reshape((4,1))\n",
    "step = 0.01\n",
    "\n",
    "combinations = []\n",
    "for i in range(4): \n",
    "    ls = [0, 1, 2, 3]\n",
    "    ls.remove(i)\n",
    "    for j in ls: \n",
    "        combinations.append((i, j))\n",
    "                            \n",
    "\n",
    "lambdas_set=[]\n",
    "for comb in combinations: \n",
    "    i, j = comb \n",
    "    new_lambdas = lambdas.copy()\n",
    "    new_lambdas[i][0] = lambdas[i][0] + step\n",
    "    new_lambdas[j][0] = lambdas[j][0] - step\n",
    "    lambdas_set.append(new_lambdas)                            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "best_valid_perplexity = 1e9\n",
    "for lambdas in lambdas_set:\n",
    "    lm = NGramInterpolation(n = n, vsize = len(vocab) + 1, total_word_count = total_wc, lambdas = lambdas)  # +1 is for <eos>\n",
    "    lm.estimate(datasets['train'])\n",
    "    perplexity_train = perplexity(lm, datasets['train'])\n",
    "    perplexity_valid = perplexity(lm, datasets['valid'])\n",
    "    if perplexity_valid < best_valid_perplexity:\n",
    "        best_valid_perplexity = perplexity_valid\n",
    "        best_paramset = lambdas\n",
    "    \n",
    "    print(\"Baseline (Interpolation, n=%d, lamdas=%s) Train Perplexity: %.3f\" % (n, str(lambdas), perplexity_train))\n",
    "    print(\"Baseline (Interpolation, n=%d, lamdas=%s) Valid Perplexity: %.3f\" % (n, str(lambdas), perplexity_valid))\n",
    "print(\"-\"*10)\n",
    "print(\"Best (Interpolation smoothing, n=%d, lamdas=%s) Valid Perplexity: %.3f\" % (n, str(best_paramset), best_valid_perplexity))\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimal Parameter Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimal Parameter Sets After Fine Tune\n",
    "\n",
    "# n = 4\n",
    "# ----------\n",
    "# Best (Interpolation smoothing, n=4, lamdas=[[0.47]\n",
    "#  [0.17]\n",
    "#  [0.33]\n",
    "#  [0.03]]) Valid Perplexity: 404.623\n",
    "# 3\n",
    "# n = 3\n",
    "# ----------\n",
    "# Best (Interpolation smoothing, n=3, lamdas=[[0.7 ]\n",
    "#  [0.01]\n",
    "#  [0.29]]) Valid Perplexity: 297.266\n",
    "# n = 2\n",
    "# ----------\n",
    "# Best (Interpolation smoothing, n=2, lamdas=[[0.32]\n",
    "#  [0.68]]) Valid Perplexity: 301.697"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now compare the performance of the two smoothing methods on the test set. Use the best hyperparameters you found for each."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline (Additive smoothing, n=2, delta=0.0050)) Valid Perplexity: 475.942\n",
      "Baseline (Additive smoothing, n=2, delta=0.0050)) Test Perplexity: 447.054\n"
     ]
    }
   ],
   "source": [
    "#The best additive smoothing model would be n = 2, delta = 0.005 \n",
    "lm_add = NGramAdditive(n = 2, delta = 0.005, vsize = len(vocab) + 1)  # +1 is for <eos>\n",
    "lm_add.estimate(datasets['train'])\n",
    "\n",
    "print(\"Baseline (Additive smoothing, n=%d, delta=%.4f)) Valid Perplexity: %.3f\" % (2, 0.005, perplexity(lm_add, datasets['valid'])))\n",
    "print(\"Baseline (Additive smoothing, n=%d, delta=%.4f)) Test Perplexity: %.3f\" % (2, 0.005, perplexity(lm_add, datasets['test'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-08T03:36:36.554090Z",
     "start_time": "2020-10-08T03:36:24.560233Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline (Interpolation, n=2, lamdas=[0.7, 0.01, 0.29])) Valid Perplexity: 297.266\n",
      "Baseline (Interpolation, n=2, lamdas=[0.7, 0.01, 0.29])) Test Perplexity: 282.715\n"
     ]
    }
   ],
   "source": [
    "#The best interpolation model in our grid search would be n = 3, lambda = [0.69, 0.02, 0.29]\n",
    "lambdas = [0.7, 0.01, 0.29]\n",
    "lm_int = NGramInterpolation(n = 3, vsize = len(vocab) + 1, total_word_count = total_wc, lambdas = lambdas)  # +1 is for <eos>\n",
    "lm_int.estimate(datasets['train'])\n",
    "\n",
    "print(\"Baseline (Interpolation, n=%d, lamdas=%s)) Valid Perplexity: %.3f\" % (2, str(lambdas), perplexity(lm_int, datasets['valid'])))\n",
    "print(\"Baseline (Interpolation, n=%d, lamdas=%s)) Test Perplexity: %.3f\" % (2, str(lambdas), perplexity(lm_int, datasets['test'])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer**:    \n",
    "From the above result we can see that the interpolation model performs better than the additive model. It is because interpolation model is a combination of different ngrams and it also leverage the trick of additive smoothing when the count of word in unigrm is zero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
